# Optimizing-Traffic-Signal-Control-with-Reinforcement-Learning-for-Road-Traffic-Management-with-DQN-

ğŸš— This repository contains an implementation of a Deep Q-Network (DQN) agent for optimizing traffic signal control in urban environments. This project explores the utilization of Reinforcement Learning (RL) techniques, specifically the Deep Q-Network (DQN) algorithm, to optimize Traffic Signal Control (TSC) in the domain of Road Traffic Management (RTM). By leveraging RL's ability to adapt to varying traffic conditions and the power of DQN in approximating optimal action-value functions, we aim to alleviate traffic congestion and improve traffic flow efficiency.

## ğŸŒŸ Overview

Traditional traffic signal control methods, such as fixed-time or actuated control, often struggle to adapt to dynamic traffic conditions, leading to inefficient traffic management and congestion. This project proposes a novel approach by leveraging the power of Deep Reinforcement Learning (DRL) to optimize traffic signal control in real-time. ğŸ”„

The DQN agent is trained using real-world traffic simulation data generated by the Simulation of Urban Mobility (SUMO) simulator. The agent learns to make optimal decisions regarding traffic light phase configurations based on the current traffic conditions (number of vehicles in each lane) at intersections. ğŸš¦

## ğŸš€ Features

- **Reinforcement Learning (RL)**: Trial-and-error learning approach for traffic signal control optimization.
- **Deep Q-Network (DQN) Agent**: The core of the project is a DQN agent that learns to optimize traffic signal control through reinforcement learning. It is  a neural network algorithm to approximate Q-values for optimal policy determination.ğŸ”
- **Experience Replay**: The agent utilizes an experience replay mechanism to store and sample past experiences for efficient and stable learning. ğŸ’¾
- **Exploration-Exploitation Strategy**: An epsilon-greedy strategy is implemented to balance exploration and exploitation during the training process. ğŸ”„
- **SUMO Integration**: The project integrates with the SUMO simulator to create realistic traffic simulations based on OpenStreetMap data. ğŸ—ºï¸
- **Real-world Data**: The agent is trained on real-world traffic simulation data, enabling it to learn and adapt to diverse traffic conditions. ğŸŒ
- **Customizable Reward Function**: The reward function for the agent can be customized to prioritize different traffic management objectives, such as minimizing waiting times or maximizing throughput. ğŸ†
- **Hyperparameter Optimization**: Tuning hyperparameters for effective learning and performance. ğŸª›



### Prerequisites

- Python 3.x ğŸ
- SUMO (Simulation of Urban Mobility) simulator ğŸš—
- PyTorch ğŸ”¥
- Numpy ğŸ“Š
- Matplotlib (for visualizations) ğŸ“ˆ
